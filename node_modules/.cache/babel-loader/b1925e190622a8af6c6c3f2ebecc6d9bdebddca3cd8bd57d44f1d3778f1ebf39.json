{"ast":null,"code":"\"use strict\";\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n      label: 0,\n      sent: function () {\n        if (t[0] & 1) throw t[1];\n        return t[1];\n      },\n      trys: [],\n      ops: []\n    },\n    f,\n    y,\n    t,\n    g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n    while (_) try {\n      if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n      if (y = 0, t) op = [op[0] & 2, t.value];\n      switch (op[0]) {\n        case 0:\n        case 1:\n          t = op;\n          break;\n        case 4:\n          _.label++;\n          return {\n            value: op[1],\n            done: false\n          };\n        case 5:\n          _.label++;\n          y = op[1];\n          op = [0];\n          continue;\n        case 7:\n          op = _.ops.pop();\n          _.trys.pop();\n          continue;\n        default:\n          if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n            _ = 0;\n            continue;\n          }\n          if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n            _.label = op[1];\n            break;\n          }\n          if (op[0] === 6 && _.label < t[1]) {\n            _.label = t[1];\n            t = op;\n            break;\n          }\n          if (t && _.label < t[2]) {\n            _.label = t[2];\n            _.ops.push(op);\n            break;\n          }\n          if (t[2]) _.ops.pop();\n          _.trys.pop();\n          continue;\n      }\n      op = body.call(thisArg, _);\n    } catch (e) {\n      op = [6, e];\n      y = 0;\n    } finally {\n      f = t = 0;\n    }\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.createTeachable = exports.TeachableMobileNet = void 0;\nvar tf = require(\"@tensorflow/tfjs\");\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\nvar tf_1 = require(\"./utils/tf\");\nvar custom_mobilenet_1 = require(\"./custom-mobilenet\");\nvar seedrandom = require(\"seedrandom\");\nvar VALIDATION_FRACTION = 0.15;\n// tslint:disable-next-line:no-any\nvar isTensor = function (c) {\n  return typeof c.dataId === 'object' && typeof c.shape === 'object';\n};\n/**\n * Converts an integer into its one-hot representation and returns\n * the data as a JS Array.\n */\nfunction flatOneHot(label, numClasses) {\n  var labelOneHot = new Array(numClasses).fill(0);\n  labelOneHot[label] = 1;\n  return labelOneHot;\n}\n/**\n * Shuffle an array of Float32Array or Samples using Fisher-Yates algorithm\n * Takes an optional seed value to make shuffling predictable\n */\nfunction fisherYates(array, seed) {\n  var _a;\n  var length = array.length;\n  // need to clone array or we'd be editing original as we goo\n  var shuffled = array.slice();\n  for (var i = length - 1; i > 0; i -= 1) {\n    var randomIndex = void 0;\n    if (seed) {\n      randomIndex = Math.floor(seed() * (i + 1));\n    } else {\n      randomIndex = Math.floor(Math.random() * (i + 1));\n    }\n    _a = [shuffled[randomIndex], shuffled[i]], shuffled[i] = _a[0], shuffled[randomIndex] = _a[1];\n  }\n  return shuffled;\n}\nvar TeachableMobileNet = /** @class */function (_super) {\n  __extends(TeachableMobileNet, _super);\n  function TeachableMobileNet(truncated, metadata) {\n    var _this = _super.call(this, tf.sequential(), metadata) || this;\n    // private __stopTrainingReject: (error: Error) => void;\n    // Number of total samples\n    _this.totalSamples = 0;\n    // Array of all the examples collected\n    _this.examples = [];\n    // the provided model is the truncated mobilenet\n    _this.truncatedModel = truncated;\n    return _this;\n  }\n  Object.defineProperty(TeachableMobileNet.prototype, \"asSequentialModel\", {\n    get: function () {\n      return this.model;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(TeachableMobileNet.prototype, \"isTrained\", {\n    /**\n     * has the teachable model been trained?\n     */\n    get: function () {\n      return !!this.model && this.model.layers && this.model.layers.length > 2;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(TeachableMobileNet.prototype, \"isPrepared\", {\n    /**\n     * has the dataset been prepared with all labels and samples processed?\n     */\n    get: function () {\n      return !!this.trainDataset;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(TeachableMobileNet.prototype, \"numClasses\", {\n    /**\n     * how many classes are in the dataset?\n     */\n    get: function () {\n      return this._metadata.labels.length;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\n   * Add a sample of data under the provided className\n   * @param className the classification this example belongs to\n   * @param sample the image / tensor that belongs in this classification\n   */\n  // public async addExample(className: number, sample: HTMLCanvasElement | tf.Tensor) {\n  TeachableMobileNet.prototype.addExample = function (className, sample) {\n    return __awaiter(this, void 0, void 0, function () {\n      var cap, example, activation;\n      return __generator(this, function (_a) {\n        cap = isTensor(sample) ? sample : tf_1.capture(sample, this._metadata.grayscale);\n        example = this.truncatedModel.predict(cap);\n        activation = example.dataSync();\n        cap.dispose();\n        example.dispose();\n        // save samples of each class separately\n        this.examples[className].push(activation);\n        // increase our sample counter\n        this.totalSamples++;\n        return [2 /*return*/];\n      });\n    });\n  };\n  /**\n   * Classify an input image / Tensor with your trained model. Return all results.\n   * @param image the input image / Tensor to classify against your model\n   * @param topK how many of the top results do you want? defautls to 3\n   */\n  TeachableMobileNet.prototype.predict = function (image, flipped) {\n    if (flipped === void 0) {\n      flipped = false;\n    }\n    return __awaiter(this, void 0, void 0, function () {\n      return __generator(this, function (_a) {\n        if (!this.model) {\n          throw new Error('Model has not been trained yet, called train() first');\n        }\n        return [2 /*return*/, _super.prototype.predict.call(this, image, flipped)];\n      });\n    });\n  };\n  /**\n   * Classify an input image / Tensor with your trained model. Return topK results\n   * @param image the input image / Tensor to classify against your model\n   * @param maxPredictions how many of the top results do you want? defautls to 3\n   * @param flipped whether to flip an image\n   */\n  TeachableMobileNet.prototype.predictTopK = function (image, maxPredictions, flipped) {\n    if (maxPredictions === void 0) {\n      maxPredictions = 10;\n    }\n    if (flipped === void 0) {\n      flipped = false;\n    }\n    return __awaiter(this, void 0, void 0, function () {\n      return __generator(this, function (_a) {\n        if (!this.model) {\n          throw new Error('Model has not been trained yet, called train() first');\n        }\n        return [2 /*return*/, _super.prototype.predictTopK.call(this, image, maxPredictions, flipped)];\n      });\n    });\n  };\n  /**\n   * process the current examples provided to calculate labels and format\n   * into proper tf.data.Dataset\n   */\n  TeachableMobileNet.prototype.prepare = function () {\n    for (var classes in this.examples) {\n      if (classes.length === 0) {\n        throw new Error('Add some examples before training');\n      }\n    }\n    var datasets = this.convertToTfDataset();\n    this.trainDataset = datasets.trainDataset;\n    this.validationDataset = datasets.validationDataset;\n  };\n  /**\n   * Process the examples by first shuffling randomly per class, then adding\n   * one-hot labels, then splitting into training/validation datsets, and finally\n   * sorting one last time\n   */\n  TeachableMobileNet.prototype.convertToTfDataset = function () {\n    // first shuffle each class individually\n    // TODO: we could basically replicate this by insterting randomly\n    for (var i = 0; i < this.examples.length; i++) {\n      this.examples[i] = fisherYates(this.examples[i], this.seed);\n    }\n    // then break into validation and test datasets\n    var trainDataset = [];\n    var validationDataset = [];\n    var _loop_1 = function (i) {\n      var y = flatOneHot(i, this_1.numClasses);\n      var classLength = this_1.examples[i].length;\n      var numValidation = Math.ceil(VALIDATION_FRACTION * classLength);\n      var numTrain = classLength - numValidation;\n      var classTrain = this_1.examples[i].slice(0, numTrain).map(function (dataArray) {\n        return {\n          data: dataArray,\n          label: y\n        };\n      });\n      var classValidation = this_1.examples[i].slice(numTrain).map(function (dataArray) {\n        return {\n          data: dataArray,\n          label: y\n        };\n      });\n      trainDataset = trainDataset.concat(classTrain);\n      validationDataset = validationDataset.concat(classValidation);\n    };\n    var this_1 = this;\n    // for each class, add samples to train and validation dataset\n    for (var i = 0; i < this.examples.length; i++) {\n      _loop_1(i);\n    }\n    // finally shuffle both train and validation datasets\n    trainDataset = fisherYates(trainDataset, this.seed);\n    validationDataset = fisherYates(validationDataset, this.seed);\n    var trainX = tf.data.array(trainDataset.map(function (sample) {\n      return sample.data;\n    }));\n    var validationX = tf.data.array(validationDataset.map(function (sample) {\n      return sample.data;\n    }));\n    var trainY = tf.data.array(trainDataset.map(function (sample) {\n      return sample.label;\n    }));\n    var validationY = tf.data.array(validationDataset.map(function (sample) {\n      return sample.label;\n    }));\n    // return tf.data dataset objects\n    return {\n      trainDataset: tf.data.zip({\n        xs: trainX,\n        ys: trainY\n      }),\n      validationDataset: tf.data.zip({\n        xs: validationX,\n        ys: validationY\n      })\n    };\n  };\n  /**\n   * Saving `model`'s topology and weights as two files\n   * (`my-model-1.json` and `my-model-1.weights.bin`) as well as\n   * a `metadata.json` file containing metadata such as text labels to be\n   * downloaded from browser.\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   */\n  TeachableMobileNet.prototype.save = function (handlerOrURL, config) {\n    return __awaiter(this, void 0, void 0, function () {\n      return __generator(this, function (_a) {\n        return [2 /*return*/, this.model.save(handlerOrURL, config)];\n      });\n    });\n  };\n  /**\n   * Train your data into a new model and join it with mobilenet\n   * @param params the parameters for the model / training\n   * @param callbacks provide callbacks to receive training events\n   */\n  TeachableMobileNet.prototype.train = function (params, callbacks) {\n    if (callbacks === void 0) {\n      callbacks = {};\n    }\n    return __awaiter(this, void 0, void 0, function () {\n      var originalOnTrainEnd, numLabels, inputShape, inputSize, varianceScaling, optimizer, trainData, validationData, history, jointModel;\n      var _this = this;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            originalOnTrainEnd = callbacks.onTrainEnd || function () {};\n            callbacks.onTrainEnd = function (logs) {\n              if (_this.__stopTrainingResolve) {\n                _this.__stopTrainingResolve();\n                _this.__stopTrainingResolve = null;\n              }\n              originalOnTrainEnd(logs);\n            };\n            // Rest of trian function\n            if (!this.isPrepared) {\n              this.prepare();\n            }\n            numLabels = this.getLabels().length;\n            tfjs_1.util.assert(numLabels === this.numClasses, function () {\n              return \"Can not train, has \" + numLabels + \" labels and \" + _this.numClasses + \" classes\";\n            });\n            inputShape = this.truncatedModel.outputs[0].shape.slice(1);\n            inputSize = tf.util.sizeFromShape(inputShape);\n            if (this.seed) {\n              varianceScaling = tf.initializers.varianceScaling({\n                seed: 3.14\n              });\n            } else {\n              varianceScaling = tf.initializers.varianceScaling({});\n            }\n            this.trainingModel = tf.sequential({\n              layers: [tf.layers.dense({\n                inputShape: [inputSize],\n                units: params.denseUnits,\n                activation: 'relu',\n                kernelInitializer: varianceScaling,\n                useBias: true\n              }), tf.layers.dense({\n                kernelInitializer: varianceScaling,\n                useBias: false,\n                activation: 'softmax',\n                units: this.numClasses\n              })]\n            });\n            optimizer = tf.train.adam(params.learningRate);\n            // const optimizer = tf.train.rmsprop(params.learningRate);\n            this.trainingModel.compile({\n              optimizer: optimizer,\n              // loss: 'binaryCrossentropy',\n              loss: 'categoricalCrossentropy',\n              metrics: ['accuracy']\n            });\n            if (!(params.batchSize > 0)) {\n              throw new Error(\"Batch size is 0 or NaN. Please choose a non-zero fraction\");\n            }\n            trainData = this.trainDataset.batch(params.batchSize);\n            validationData = this.validationDataset.batch(params.batchSize);\n            return [4 /*yield*/, this.trainingModel.fitDataset(trainData, {\n              epochs: params.epochs,\n              validationData: validationData,\n              callbacks: callbacks\n            })];\n          case 1:\n            history = _a.sent();\n            jointModel = tf.sequential();\n            jointModel.add(this.truncatedModel);\n            jointModel.add(this.trainingModel);\n            this.model = jointModel;\n            optimizer.dispose(); // cleanup of memory\n            return [2 /*return*/, this.model];\n        }\n      });\n    });\n  };\n  /*\n   * Setup the exampls array to hold samples per class\n   */\n  TeachableMobileNet.prototype.prepareDataset = function () {\n    for (var i = 0; i < this.numClasses; i++) {\n      this.examples[i] = [];\n    }\n  };\n  TeachableMobileNet.prototype.setLabel = function (index, label) {\n    this._metadata.labels[index] = label;\n  };\n  TeachableMobileNet.prototype.setLabels = function (labels) {\n    this._metadata.labels = labels;\n    this.prepareDataset();\n  };\n  TeachableMobileNet.prototype.getLabel = function (index) {\n    return this._metadata.labels[index];\n  };\n  TeachableMobileNet.prototype.getLabels = function () {\n    return this._metadata.labels;\n  };\n  TeachableMobileNet.prototype.setName = function (name) {\n    this._metadata.modelName = name;\n  };\n  TeachableMobileNet.prototype.getName = function () {\n    return this._metadata.modelName;\n  };\n  TeachableMobileNet.prototype.stopTraining = function () {\n    var _this = this;\n    var promise = new Promise(function (resolve, reject) {\n      _this.trainingModel.stopTraining = true;\n      _this.__stopTrainingResolve = resolve;\n      // this.__stopTrainingReject = reject;\n    });\n    return promise;\n  };\n  TeachableMobileNet.prototype.dispose = function () {\n    this.trainingModel.dispose();\n    _super.prototype.dispose.call(this);\n  };\n  /*\n   * Calculate each class accuracy using the validation dataset\n   */\n  TeachableMobileNet.prototype.calculateAccuracyPerClass = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var validationXs, validationYs, batchSize, iterations, batchesX, batchesY, itX, itY, allX, allY, i, batchedXTensor, batchedXPredictionTensor, argMaxX, batchedYTensor, argMaxY, reference, predictions, i;\n      var _this = this;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            validationXs = this.validationDataset.mapAsync(function (dataset) {\n              return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                  return [2 /*return*/, dataset.xs];\n                });\n              });\n            });\n            validationYs = this.validationDataset.mapAsync(function (dataset) {\n              return __awaiter(_this, void 0, void 0, function () {\n                return __generator(this, function (_a) {\n                  return [2 /*return*/, dataset.ys];\n                });\n              });\n            });\n            batchSize = Math.min(validationYs.size, 32);\n            iterations = Math.ceil(validationYs.size / batchSize);\n            batchesX = validationXs.batch(batchSize);\n            batchesY = validationYs.batch(batchSize);\n            return [4 /*yield*/, batchesX.iterator()];\n          case 1:\n            itX = _a.sent();\n            return [4 /*yield*/, batchesY.iterator()];\n          case 2:\n            itY = _a.sent();\n            allX = [];\n            allY = [];\n            i = 0;\n            _a.label = 3;\n          case 3:\n            if (!(i < iterations)) return [3 /*break*/, 7];\n            return [4 /*yield*/, itX.next()];\n          case 4:\n            batchedXTensor = _a.sent();\n            batchedXPredictionTensor = this.trainingModel.predict(batchedXTensor.value);\n            argMaxX = batchedXPredictionTensor.argMax(1);\n            allX.push(argMaxX);\n            return [4 /*yield*/, itY.next()];\n          case 5:\n            batchedYTensor = _a.sent();\n            argMaxY = batchedYTensor.value.argMax(1);\n            allY.push(argMaxY);\n            // 3. dispose of all our tensors\n            batchedXTensor.value.dispose();\n            batchedXPredictionTensor.dispose();\n            batchedYTensor.value.dispose();\n            _a.label = 6;\n          case 6:\n            i++;\n            return [3 /*break*/, 3];\n          case 7:\n            reference = tf.concat(allY);\n            predictions = tf.concat(allX);\n            // only if we concatenated more than one tensor for preference and reference\n            if (iterations !== 1) {\n              for (i = 0; i < allX.length; i++) {\n                allX[i].dispose();\n                allY[i].dispose();\n              }\n            }\n            return [2 /*return*/, {\n              reference: reference,\n              predictions: predictions\n            }];\n        }\n      });\n    });\n  };\n  /*\n   * optional seed for predictable shuffling of dataset\n   */\n  TeachableMobileNet.prototype.setSeed = function (seed) {\n    this.seed = seedrandom(seed);\n  };\n  return TeachableMobileNet;\n}(custom_mobilenet_1.CustomMobileNet);\nexports.TeachableMobileNet = TeachableMobileNet;\nfunction createTeachable(metadata, modelOptions) {\n  return __awaiter(this, void 0, void 0, function () {\n    var mobilenet;\n    return __generator(this, function (_a) {\n      switch (_a.label) {\n        case 0:\n          return [4 /*yield*/, custom_mobilenet_1.loadTruncatedMobileNet(modelOptions)];\n        case 1:\n          mobilenet = _a.sent();\n          return [2 /*return*/, new TeachableMobileNet(mobilenet, metadata)];\n      }\n    });\n  });\n}\nexports.createTeachable = createTeachable;","map":{"version":3,"names":["tf","require","tfjs_1","tf_1","custom_mobilenet_1","seedrandom","VALIDATION_FRACTION","isTensor","c","dataId","shape","flatOneHot","label","numClasses","labelOneHot","Array","fill","fisherYates","array","seed","length","shuffled","slice","i","randomIndex","Math","floor","random","_a","TeachableMobileNet","_super","__extends","truncated","metadata","_this","call","sequential","totalSamples","examples","truncatedModel","Object","defineProperty","prototype","get","model","layers","trainDataset","_metadata","labels","addExample","className","sample","cap","capture","grayscale","example","predict","activation","dataSync","dispose","push","image","flipped","Error","predictTopK","maxPredictions","prepare","classes","datasets","convertToTfDataset","validationDataset","y","this_1","classLength","numValidation","ceil","numTrain","classTrain","map","dataArray","data","classValidation","concat","trainX","validationX","trainY","validationY","zip","xs","ys","save","handlerOrURL","config","train","params","callbacks","originalOnTrainEnd","onTrainEnd","logs","__stopTrainingResolve","isPrepared","numLabels","getLabels","util","assert","inputShape","outputs","inputSize","sizeFromShape","varianceScaling","initializers","trainingModel","dense","units","denseUnits","kernelInitializer","useBias","optimizer","adam","learningRate","compile","loss","metrics","batchSize","trainData","batch","validationData","fitDataset","epochs","history","sent","jointModel","add","prepareDataset","setLabel","index","setLabels","getLabel","setName","name","modelName","getName","stopTraining","promise","Promise","resolve","reject","calculateAccuracyPerClass","validationXs","mapAsync","dataset","__awaiter","validationYs","min","size","iterations","batchesX","batchesY","iterator","itX","itY","allX","allY","next","batchedXTensor","batchedXPredictionTensor","value","argMaxX","argMax","batchedYTensor","argMaxY","reference","predictions","setSeed","CustomMobileNet","exports","createTeachable","modelOptions","loadTruncatedMobileNet","mobilenet"],"sources":["C:\\Users\\Chris Littlejohn\\Downloads\\barcode-matcher-final-project (1)\\node_modules\\@teachablemachine\\image\\src\\teachable-mobilenet.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\nimport { util, Rank } from '@tensorflow/tfjs';\nimport { capture } from './utils/tf';\nimport { TensorContainer } from '@tensorflow/tfjs-core/dist/tensor_types';\nimport { CustomCallbackArgs } from '@tensorflow/tfjs';\nimport { CustomMobileNet,\n    Metadata,\n    loadTruncatedMobileNet,\n    ClassifierInputSource,\n    ModelOptions\n} from './custom-mobilenet';\nimport * as seedrandom from 'seedrandom';\nimport { Initializer } from '@tensorflow/tfjs-layers/dist/initializers';\n\nconst VALIDATION_FRACTION = 0.15;\n\nexport interface TrainingParameters {\n    denseUnits: number;\n    epochs: number;\n    learningRate: number;\n    batchSize: number;\n}\n\ninterface Sample {\n    data: Float32Array;\n    label: number[];\n}\n\n// tslint:disable-next-line:no-any\nconst isTensor = (c: any): c is tf.Tensor =>\n    typeof c.dataId === 'object' && typeof c.shape === 'object';\n\n/**\n * Converts an integer into its one-hot representation and returns\n * the data as a JS Array.\n */\nfunction flatOneHot(label: number, numClasses: number) {\n    const labelOneHot = new Array(numClasses).fill(0) as number[];\n    labelOneHot[label] = 1;\n\n    return labelOneHot;\n}\n\n/**\n * Shuffle an array of Float32Array or Samples using Fisher-Yates algorithm\n * Takes an optional seed value to make shuffling predictable\n */\nfunction fisherYates(array: Float32Array[] | Sample[], seed?: seedrandom.prng) {\n    const length = array.length;\n\n    // need to clone array or we'd be editing original as we goo\n    const shuffled = array.slice();\n\n    for (let i = (length - 1); i > 0; i -= 1) {\n        let randomIndex ;\n        if (seed) {\n            randomIndex = Math.floor(seed() * (i + 1));\n        }\n        else {\n            randomIndex = Math.floor(Math.random() * (i + 1));\n        }\n\n        [shuffled[i], shuffled[randomIndex]] = [shuffled[randomIndex],shuffled[i]];\n    }\n\n    return shuffled;\n}\n\nexport class TeachableMobileNet extends CustomMobileNet {\n    /**\n     * the training model for transfer learning\n     */\n    protected trainingModel: tf.LayersModel;\n\n    /**\n     * Training and validation datasets\n     */\n    private trainDataset: tf.data.Dataset<TensorContainer>;\n    private validationDataset: tf.data.Dataset<TensorContainer>;\n\n    private __stopTrainingResolve: () => void;\n    // private __stopTrainingReject: (error: Error) => void;\n\n    // Number of total samples\n    private totalSamples = 0;\n\n    // Array of all the examples collected\n    public examples: Float32Array[][] = [];\n\n    // Optional seed to make shuffling of data predictable\n    private seed: seedrandom.prng;\n\n    constructor(truncated: tf.LayersModel, metadata: Partial<Metadata>) {\n        super(tf.sequential(), metadata);\n        // the provided model is the truncated mobilenet\n        this.truncatedModel = truncated;\n    }\n\n    public get asSequentialModel() {\n        return this.model as tf.Sequential;\n    }\n\n\n    /**\n     * has the teachable model been trained?\n     */\n    public get isTrained() {\n        return !!this.model && this.model.layers && this.model.layers.length > 2;\n    }\n\n    /**\n     * has the dataset been prepared with all labels and samples processed?\n     */\n    public get isPrepared() {\n        return !!this.trainDataset;\n    }\n\n    /**\n     * how many classes are in the dataset?\n     */\n    public get numClasses(): number {\n        return this._metadata.labels.length;\n    }\n\n    /**\n     * Add a sample of data under the provided className\n     * @param className the classification this example belongs to\n     * @param sample the image / tensor that belongs in this classification\n     */\n    // public async addExample(className: number, sample: HTMLCanvasElement | tf.Tensor) {\n    public async addExample(className: number, sample: HTMLImageElement | HTMLCanvasElement | tf.Tensor) {\n        const cap = isTensor(sample) ? sample : capture(sample, this._metadata.grayscale);\n        const example = this.truncatedModel.predict(cap) as tf.Tensor;\n\n        const activation = example.dataSync() as Float32Array;\n        cap.dispose();\n        example.dispose();\n\n        // save samples of each class separately\n        this.examples[className].push(activation);\n\n        // increase our sample counter\n        this.totalSamples++;\n    }\n\n    /**\n     * Classify an input image / Tensor with your trained model. Return all results.\n     * @param image the input image / Tensor to classify against your model\n     * @param topK how many of the top results do you want? defautls to 3\n     */\n    public async predict(image: ClassifierInputSource, flipped = false) {\n        if (!this.model) {\n            throw new Error('Model has not been trained yet, called train() first');\n        }\n        return super.predict(image, flipped);\n    }\n\n    /**\n     * Classify an input image / Tensor with your trained model. Return topK results\n     * @param image the input image / Tensor to classify against your model\n     * @param maxPredictions how many of the top results do you want? defautls to 3\n     * @param flipped whether to flip an image\n     */\n    public async predictTopK(image: ClassifierInputSource, maxPredictions = 10, flipped = false, ) {\n        if (!this.model) {\n            throw new Error('Model has not been trained yet, called train() first');\n        }\n        return super.predictTopK(image, maxPredictions, flipped);\n    }\n\n    /**\n     * process the current examples provided to calculate labels and format\n     * into proper tf.data.Dataset\n     */\n    public prepare() {\n        for (const classes in this.examples){\n            if (classes.length === 0) {\n                throw new Error('Add some examples before training');\n            }\n        }\n\n        const datasets = this.convertToTfDataset();\n        this.trainDataset = datasets.trainDataset;\n        this.validationDataset = datasets.validationDataset;\n    }\n\n    /**\n     * Process the examples by first shuffling randomly per class, then adding\n     * one-hot labels, then splitting into training/validation datsets, and finally\n     * sorting one last time\n     */\n    private convertToTfDataset() {\n        // first shuffle each class individually\n        // TODO: we could basically replicate this by insterting randomly\n        for (let i = 0; i < this.examples.length; i++) {\n            this.examples[i] = fisherYates(this.examples[i], this.seed) as Float32Array[];\n        }\n\n        // then break into validation and test datasets\n\n        let trainDataset: Sample[] = [];\n        let validationDataset: Sample[] = [];\n\n        // for each class, add samples to train and validation dataset\n        for (let i = 0; i < this.examples.length; i++) {\n            const y = flatOneHot(i, this.numClasses);\n\n            const classLength = this.examples[i].length;\n            const numValidation = Math.ceil(VALIDATION_FRACTION * classLength);\n            const numTrain = classLength - numValidation;\n\n            const classTrain = this.examples[i].slice(0, numTrain).map((dataArray) => {\n                return { data: dataArray, label: y };\n            });\n\n            const classValidation = this.examples[i].slice(numTrain).map((dataArray) => {\n                return { data: dataArray, label: y };\n            });\n\n            trainDataset = trainDataset.concat(classTrain);\n            validationDataset = validationDataset.concat(classValidation);\n        }\n\n        // finally shuffle both train and validation datasets\n        trainDataset = fisherYates(trainDataset, this.seed) as Sample[];\n        validationDataset = fisherYates(validationDataset, this.seed) as Sample[];\n\n        const trainX = tf.data.array(trainDataset.map(sample => sample.data));\n        const validationX = tf.data.array(validationDataset.map(sample => sample.data));\n        const trainY = tf.data.array(trainDataset.map(sample => sample.label));\n        const validationY = tf.data.array(validationDataset.map(sample => sample.label));\n\n        // return tf.data dataset objects\n        return {\n            trainDataset: tf.data.zip({ xs: trainX,  ys: trainY}),\n            validationDataset: tf.data.zip({ xs: validationX,  ys: validationY})\n        };\n    }\n\n    /**\n     * Saving `model`'s topology and weights as two files\n     * (`my-model-1.json` and `my-model-1.weights.bin`) as well as\n     * a `metadata.json` file containing metadata such as text labels to be\n     * downloaded from browser.\n     * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n     * scheme-based string shortcut for `IOHandler`.\n     * @param config Options for saving the model.\n     * @returns A `Promise` of `SaveResult`, which summarizes the result of\n     * the saving, such as byte sizes of the saved artifacts for the model's\n     *   topology and weight values.\n     */\n    public async save(handlerOrURL: tf.io.IOHandler | string, config?: tf.io.SaveConfig): Promise<tf.io.SaveResult> {\n        return this.model.save(handlerOrURL, config);\n    }\n\n    /**\n     * Train your data into a new model and join it with mobilenet\n     * @param params the parameters for the model / training\n     * @param callbacks provide callbacks to receive training events\n     */\n    public async train(params: TrainingParameters, callbacks: CustomCallbackArgs = {}) {\n        // Add callback for onTrainEnd in case of early stop\n        const originalOnTrainEnd = callbacks.onTrainEnd || (() => {});\n        callbacks.onTrainEnd = (logs: tf.Logs) => {\n            if (this.__stopTrainingResolve) {\n                this.__stopTrainingResolve();\n                this.__stopTrainingResolve = null;\n            }\n            originalOnTrainEnd(logs);\n        };\n        \n        // Rest of trian function\n        if (!this.isPrepared) {\n            this.prepare();\n        }\n\n        const numLabels = this.getLabels().length;\n        util.assert(\n            numLabels === this.numClasses,\n            () => `Can not train, has ${numLabels} labels and ${this.numClasses} classes`);\n\n        const inputShape = this.truncatedModel.outputs[0].shape.slice(1); // [ 7 x 7 x 1280]\n        const inputSize = tf.util.sizeFromShape(inputShape);\n\n        // in case we need to use a seed for predictable training\n        let varianceScaling: Initializer;\n        if (this.seed) {\n            varianceScaling = tf.initializers.varianceScaling({ seed: 3.14});\n        }\n        else {\n            varianceScaling = tf.initializers.varianceScaling({});\n        }\n\n        this.trainingModel = tf.sequential({\n            layers: [\n                tf.layers.dense({\n                    inputShape: [inputSize],\n                    units: params.denseUnits,\n                    activation: 'relu',\n                    kernelInitializer: varianceScaling, // 'varianceScaling'\n                    useBias: true\n                }),\n                tf.layers.dense({\n                    kernelInitializer: varianceScaling, // 'varianceScaling'\n                    useBias: false,\n                    activation: 'softmax',\n                    units: this.numClasses\n                })\n            ]\n        });\n\n        const optimizer = tf.train.adam(params.learningRate);\n        // const optimizer = tf.train.rmsprop(params.learningRate);\n\n        this.trainingModel.compile({\n            optimizer,\n            // loss: 'binaryCrossentropy',\n            loss: 'categoricalCrossentropy',\n            metrics: ['accuracy']\n        });\n\n        if (!(params.batchSize > 0)) {\n            throw new Error(\n            `Batch size is 0 or NaN. Please choose a non-zero fraction`\n            );\n        }\n\n        const trainData = this.trainDataset.batch(params.batchSize);\n        const validationData = this.validationDataset.batch(params.batchSize);\n\n        // For debugging: check for shuffle or result from trainDataset\n        /*\n        await trainDataset.forEach((e: tf.Tensor[]) => {\n            console.log(e);\n        })\n        */\n\n        const history = await this.trainingModel.fitDataset(trainData, {\n            epochs: params.epochs,\n            validationData,\n            callbacks\n        });\n\n        const jointModel = tf.sequential();\n        jointModel.add(this.truncatedModel);\n        jointModel.add(this.trainingModel);\n        this.model = jointModel;\n\n        optimizer.dispose(); // cleanup of memory\n\n        return this.model;\n    }\n\n    /*\n     * Setup the exampls array to hold samples per class\n     */\n    public prepareDataset() {\n        for (let i = 0; i < this.numClasses; i++) {\n            this.examples[i] = [];\n        }\n    }\n\n    public setLabel(index: number, label: string) {\n        this._metadata.labels[index] = label;\n    }\n\n    public setLabels(labels: string[]) {\n        this._metadata.labels = labels;\n        this.prepareDataset();\n    }\n\n    public getLabel(index: number) {\n        return this._metadata.labels[index];\n    }\n\n    public getLabels() {\n        return this._metadata.labels;\n    }\n\n    public setName(name: string) {\n        this._metadata.modelName = name;\n    }\n\n    public getName() {\n        return this._metadata.modelName;\n    }\n\n    public stopTraining() {  \n        const promise = new Promise((resolve, reject) => {\n            this.trainingModel.stopTraining = true;\n            this.__stopTrainingResolve = resolve;\n            // this.__stopTrainingReject = reject;\n        });\n        \n        return promise;\n    }\n\n    public dispose() {\n        this.trainingModel.dispose();\n        super.dispose();\n    }\n\n    /* \n     * Calculate each class accuracy using the validation dataset\n     */\n    public async calculateAccuracyPerClass() {\n        const validationXs = this.validationDataset.mapAsync(async (dataset: TensorContainer) => {\n            return (dataset as { xs: TensorContainer, ys: TensorContainer}).xs;\n        });\n        const validationYs = this.validationDataset.mapAsync(async (dataset: TensorContainer) => {\n            return (dataset as { xs: TensorContainer, ys: TensorContainer}).ys;\n        });\n\n        // we need to split our validation data into batches in case it is too large to fit in memory\n        const batchSize = Math.min(validationYs.size, 32);\n        const iterations = Math.ceil(validationYs.size / batchSize);\n\n        const batchesX = validationXs.batch(batchSize);\n        const batchesY = validationYs.batch(batchSize);\n        const itX = await batchesX.iterator();\n        const itY = await batchesY.iterator();\n        const allX = [];\n        const allY = [];\n\n        for (let i = 0; i < iterations; i++) {\n            // 1. get the prediction values in batches\n            const batchedXTensor = await itX.next();\n            const batchedXPredictionTensor = this.trainingModel.predict(batchedXTensor.value) as tf.Tensor;\n            const argMaxX = batchedXPredictionTensor.argMax(1); // Returns the indices of the max values along an axis\n            allX.push(argMaxX);\n\n            // 2. get the ground truth label values in batches\n            const batchedYTensor = await itY.next();\n            const argMaxY = batchedYTensor.value.argMax(1); // Returns the indices of the max values along an axis\n            allY.push(argMaxY);\n\n            // 3. dispose of all our tensors\n            batchedXTensor.value.dispose();\n            batchedXPredictionTensor.dispose();\n            batchedYTensor.value.dispose();\n        }\n\n        // concatenate all the results of the batches\n        const reference = tf.concat(allY); // this is the ground truth\n        const predictions = tf.concat(allX); // this is the prediction our model is guessing\n\n        // only if we concatenated more than one tensor for preference and reference\n        if (iterations !== 1) {\n            for (let i = 0; i < allX.length; i++) {\n                allX[i].dispose();\n                allY[i].dispose();\n            }\n        }\n\n        return { reference, predictions };\n    }\n\n    /*\n     * optional seed for predictable shuffling of dataset\n     */\n    public setSeed(seed: string) {\n        this.seed = seedrandom(seed);\n    }\n}\n\nexport async function createTeachable(metadata: Partial<Metadata>, modelOptions?: ModelOptions) {\n    const mobilenet = await loadTruncatedMobileNet(modelOptions);\n    return new TeachableMobileNet(mobilenet, metadata);\n}\n"],"mappings":";;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,IAAAA,EAAA,GAAAC,OAAA;AACA,IAAAC,MAAA,GAAAD,OAAA;AACA,IAAAE,IAAA,GAAAF,OAAA;AAGA,IAAAG,kBAAA,GAAAH,OAAA;AAMA,IAAAI,UAAA,GAAAJ,OAAA;AAGA,IAAMK,mBAAmB,GAAG,IAAI;AAchC;AACA,IAAMC,QAAQ,GAAG,SAAAA,CAACC,CAAM;EACpB,cAAOA,CAAC,CAACC,MAAM,KAAK,QAAQ,IAAI,OAAOD,CAAC,CAACE,KAAK,KAAK,QAAQ;AAA3D,CAA2D;AAE/D;;;;AAIA,SAASC,UAAUA,CAACC,KAAa,EAAEC,UAAkB;EACjD,IAAMC,WAAW,GAAG,IAAIC,KAAK,CAACF,UAAU,CAAC,CAACG,IAAI,CAAC,CAAC,CAAa;EAC7DF,WAAW,CAACF,KAAK,CAAC,GAAG,CAAC;EAEtB,OAAOE,WAAW;AACtB;AAEA;;;;AAIA,SAASG,WAAWA,CAACC,KAAgC,EAAEC,IAAsB;;EACzE,IAAMC,MAAM,GAAGF,KAAK,CAACE,MAAM;EAE3B;EACA,IAAMC,QAAQ,GAAGH,KAAK,CAACI,KAAK,EAAE;EAE9B,KAAK,IAAIC,CAAC,GAAIH,MAAM,GAAG,CAAE,EAAEG,CAAC,GAAG,CAAC,EAAEA,CAAC,IAAI,CAAC,EAAE;IACtC,IAAIC,WAAW;IACf,IAAIL,IAAI,EAAE;MACNK,WAAW,GAAGC,IAAI,CAACC,KAAK,CAACP,IAAI,EAAE,IAAII,CAAC,GAAG,CAAC,CAAC,CAAC;KAC7C,MACI;MACDC,WAAW,GAAGC,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,EAAE,IAAIJ,CAAC,GAAG,CAAC,CAAC,CAAC;;IAGrDK,EAAA,GAAuC,CAACP,QAAQ,CAACG,WAAW,CAAC,EAACH,QAAQ,CAACE,CAAC,CAAC,CAAC,EAAzEF,QAAQ,CAACE,CAAC,CAAC,GAAAK,EAAA,KAAEP,QAAQ,CAACG,WAAW,CAAC,GAAAI,EAAA;;EAGvC,OAAOP,QAAQ;AACnB;AAEA,IAAAQ,kBAAA,0BAAAC,MAAA;EAAwCC,SAAA,CAAAF,kBAAA,EAAAC,MAAA;EAwBpC,SAAAD,mBAAYG,SAAyB,EAAEC,QAA2B;IAAlE,IAAAC,KAAA,GACIJ,MAAA,CAAAK,IAAA,OAAMnC,EAAE,CAACoC,UAAU,EAAE,EAAEH,QAAQ,CAAC;IAZpC;IAEA;IACQC,KAAA,CAAAG,YAAY,GAAG,CAAC;IAExB;IACOH,KAAA,CAAAI,QAAQ,GAAqB,EAAE;IAOlC;IACAJ,KAAI,CAACK,cAAc,GAAGP,SAAS;;EACnC;EAEAQ,MAAA,CAAAC,cAAA,CAAWZ,kBAAA,CAAAa,SAAA,qBAAiB;SAA5B,SAAAC,CAAA;MACI,OAAO,IAAI,CAACC,KAAsB;IACtC,CAAC;;;;EAMDJ,MAAA,CAAAC,cAAA,CAAWZ,kBAAA,CAAAa,SAAA,aAAS;IAHpB;;;SAGA,SAAAC,CAAA;MACI,OAAO,CAAC,CAAC,IAAI,CAACC,KAAK,IAAI,IAAI,CAACA,KAAK,CAACC,MAAM,IAAI,IAAI,CAACD,KAAK,CAACC,MAAM,CAACzB,MAAM,GAAG,CAAC;IAC5E,CAAC;;;;EAKDoB,MAAA,CAAAC,cAAA,CAAWZ,kBAAA,CAAAa,SAAA,cAAU;IAHrB;;;SAGA,SAAAC,CAAA;MACI,OAAO,CAAC,CAAC,IAAI,CAACG,YAAY;IAC9B,CAAC;;;;EAKDN,MAAA,CAAAC,cAAA,CAAWZ,kBAAA,CAAAa,SAAA,cAAU;IAHrB;;;SAGA,SAAAC,CAAA;MACI,OAAO,IAAI,CAACI,SAAS,CAACC,MAAM,CAAC5B,MAAM;IACvC,CAAC;;;;EAED;;;;;EAKA;EACaS,kBAAA,CAAAa,SAAA,CAAAO,UAAU,GAAvB,UAAwBC,SAAiB,EAAEC,MAAwD;;;;QACzFC,GAAG,GAAG7C,QAAQ,CAAC4C,MAAM,CAAC,GAAGA,MAAM,GAAGhD,IAAA,CAAAkD,OAAO,CAACF,MAAM,EAAE,IAAI,CAACJ,SAAS,CAACO,SAAS,CAAC;QAC3EC,OAAO,GAAG,IAAI,CAAChB,cAAc,CAACiB,OAAO,CAACJ,GAAG,CAAc;QAEvDK,UAAU,GAAGF,OAAO,CAACG,QAAQ,EAAkB;QACrDN,GAAG,CAACO,OAAO,EAAE;QACbJ,OAAO,CAACI,OAAO,EAAE;QAEjB;QACA,IAAI,CAACrB,QAAQ,CAACY,SAAS,CAAC,CAACU,IAAI,CAACH,UAAU,CAAC;QAEzC;QACA,IAAI,CAACpB,YAAY,EAAE;;;;GACtB;EAED;;;;;EAKaR,kBAAA,CAAAa,SAAA,CAAAc,OAAO,GAApB,UAAqBK,KAA4B,EAAEC,OAAe;IAAf,IAAAA,OAAA;MAAAA,OAAA,QAAe;IAAA;;;QAC9D,IAAI,CAAC,IAAI,CAAClB,KAAK,EAAE;UACb,MAAM,IAAImB,KAAK,CAAC,sDAAsD,CAAC;;QAE3E,sBAAOjC,MAAA,CAAAY,SAAA,CAAMc,OAAO,CAAArB,IAAA,OAAC0B,KAAK,EAAEC,OAAO,CAAC;;;GACvC;EAED;;;;;;EAMajC,kBAAA,CAAAa,SAAA,CAAAsB,WAAW,GAAxB,UAAyBH,KAA4B,EAAEI,cAAmB,EAAEH,OAAe;IAApC,IAAAG,cAAA;MAAAA,cAAA,KAAmB;IAAA;IAAE,IAAAH,OAAA;MAAAA,OAAA,QAAe;IAAA;;;QACvF,IAAI,CAAC,IAAI,CAAClB,KAAK,EAAE;UACb,MAAM,IAAImB,KAAK,CAAC,sDAAsD,CAAC;;QAE3E,sBAAOjC,MAAA,CAAAY,SAAA,CAAMsB,WAAW,CAAA7B,IAAA,OAAC0B,KAAK,EAAEI,cAAc,EAAEH,OAAO,CAAC;;;GAC3D;EAED;;;;EAIOjC,kBAAA,CAAAa,SAAA,CAAAwB,OAAO,GAAd;IACI,KAAK,IAAMC,OAAO,IAAI,IAAI,CAAC7B,QAAQ,EAAC;MAChC,IAAI6B,OAAO,CAAC/C,MAAM,KAAK,CAAC,EAAE;QACtB,MAAM,IAAI2C,KAAK,CAAC,mCAAmC,CAAC;;;IAI5D,IAAMK,QAAQ,GAAG,IAAI,CAACC,kBAAkB,EAAE;IAC1C,IAAI,CAACvB,YAAY,GAAGsB,QAAQ,CAACtB,YAAY;IACzC,IAAI,CAACwB,iBAAiB,GAAGF,QAAQ,CAACE,iBAAiB;EACvD,CAAC;EAED;;;;;EAKQzC,kBAAA,CAAAa,SAAA,CAAA2B,kBAAkB,GAA1B;IACI;IACA;IACA,KAAK,IAAI9C,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACe,QAAQ,CAAClB,MAAM,EAAEG,CAAC,EAAE,EAAE;MAC3C,IAAI,CAACe,QAAQ,CAACf,CAAC,CAAC,GAAGN,WAAW,CAAC,IAAI,CAACqB,QAAQ,CAACf,CAAC,CAAC,EAAE,IAAI,CAACJ,IAAI,CAAmB;;IAGjF;IAEA,IAAI2B,YAAY,GAAa,EAAE;IAC/B,IAAIwB,iBAAiB,GAAa,EAAE;4BAG3B/C,CAAC;MACN,IAAMgD,CAAC,GAAG5D,UAAU,CAACY,CAAC,EAAEiD,MAAA,CAAK3D,UAAU,CAAC;MAExC,IAAM4D,WAAW,GAAGD,MAAA,CAAKlC,QAAQ,CAACf,CAAC,CAAC,CAACH,MAAM;MAC3C,IAAMsD,aAAa,GAAGjD,IAAI,CAACkD,IAAI,CAACrE,mBAAmB,GAAGmE,WAAW,CAAC;MAClE,IAAMG,QAAQ,GAAGH,WAAW,GAAGC,aAAa;MAE5C,IAAMG,UAAU,GAAGL,MAAA,CAAKlC,QAAQ,CAACf,CAAC,CAAC,CAACD,KAAK,CAAC,CAAC,EAAEsD,QAAQ,CAAC,CAACE,GAAG,CAAC,UAACC,SAAS;QACjE,OAAO;UAAEC,IAAI,EAAED,SAAS;UAAEnE,KAAK,EAAE2D;QAAC,CAAE;MACxC,CAAC,CAAC;MAEF,IAAMU,eAAe,GAAGT,MAAA,CAAKlC,QAAQ,CAACf,CAAC,CAAC,CAACD,KAAK,CAACsD,QAAQ,CAAC,CAACE,GAAG,CAAC,UAACC,SAAS;QACnE,OAAO;UAAEC,IAAI,EAAED,SAAS;UAAEnE,KAAK,EAAE2D;QAAC,CAAE;MACxC,CAAC,CAAC;MAEFzB,YAAY,GAAGA,YAAY,CAACoC,MAAM,CAACL,UAAU,CAAC;MAC9CP,iBAAiB,GAAGA,iBAAiB,CAACY,MAAM,CAACD,eAAe,CAAC;;;IAjBjE;IACA,KAAK,IAAI1D,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACe,QAAQ,CAAClB,MAAM,EAAEG,CAAC,EAAE;cAApCA,CAAC;;IAmBV;IACAuB,YAAY,GAAG7B,WAAW,CAAC6B,YAAY,EAAE,IAAI,CAAC3B,IAAI,CAAa;IAC/DmD,iBAAiB,GAAGrD,WAAW,CAACqD,iBAAiB,EAAE,IAAI,CAACnD,IAAI,CAAa;IAEzE,IAAMgE,MAAM,GAAGnF,EAAE,CAACgF,IAAI,CAAC9D,KAAK,CAAC4B,YAAY,CAACgC,GAAG,CAAC,UAAA3B,MAAM;MAAI,OAAAA,MAAM,CAAC6B,IAAI;IAAX,CAAW,CAAC,CAAC;IACrE,IAAMI,WAAW,GAAGpF,EAAE,CAACgF,IAAI,CAAC9D,KAAK,CAACoD,iBAAiB,CAACQ,GAAG,CAAC,UAAA3B,MAAM;MAAI,OAAAA,MAAM,CAAC6B,IAAI;IAAX,CAAW,CAAC,CAAC;IAC/E,IAAMK,MAAM,GAAGrF,EAAE,CAACgF,IAAI,CAAC9D,KAAK,CAAC4B,YAAY,CAACgC,GAAG,CAAC,UAAA3B,MAAM;MAAI,OAAAA,MAAM,CAACvC,KAAK;IAAZ,CAAY,CAAC,CAAC;IACtE,IAAM0E,WAAW,GAAGtF,EAAE,CAACgF,IAAI,CAAC9D,KAAK,CAACoD,iBAAiB,CAACQ,GAAG,CAAC,UAAA3B,MAAM;MAAI,OAAAA,MAAM,CAACvC,KAAK;IAAZ,CAAY,CAAC,CAAC;IAEhF;IACA,OAAO;MACHkC,YAAY,EAAE9C,EAAE,CAACgF,IAAI,CAACO,GAAG,CAAC;QAAEC,EAAE,EAAEL,MAAM;QAAGM,EAAE,EAAEJ;MAAM,CAAC,CAAC;MACrDf,iBAAiB,EAAEtE,EAAE,CAACgF,IAAI,CAACO,GAAG,CAAC;QAAEC,EAAE,EAAEJ,WAAW;QAAGK,EAAE,EAAEH;MAAW,CAAC;KACtE;EACL,CAAC;EAED;;;;;;;;;;;;EAYazD,kBAAA,CAAAa,SAAA,CAAAgD,IAAI,GAAjB,UAAkBC,YAAsC,EAAEC,MAAyB;;;QAC/E,sBAAO,IAAI,CAAChD,KAAK,CAAC8C,IAAI,CAACC,YAAY,EAAEC,MAAM,CAAC;;;GAC/C;EAED;;;;;EAKa/D,kBAAA,CAAAa,SAAA,CAAAmD,KAAK,GAAlB,UAAmBC,MAA0B,EAAEC,SAAkC;IAAlC,IAAAA,SAAA;MAAAA,SAAA,KAAkC;IAAA;;;;;;;YAEvEC,kBAAkB,GAAGD,SAAS,CAACE,UAAU,IAAK,aAAO,CAAE;YAC7DF,SAAS,CAACE,UAAU,GAAG,UAACC,IAAa;cACjC,IAAIhE,KAAI,CAACiE,qBAAqB,EAAE;gBAC5BjE,KAAI,CAACiE,qBAAqB,EAAE;gBAC5BjE,KAAI,CAACiE,qBAAqB,GAAG,IAAI;;cAErCH,kBAAkB,CAACE,IAAI,CAAC;YAC5B,CAAC;YAED;YACA,IAAI,CAAC,IAAI,CAACE,UAAU,EAAE;cAClB,IAAI,CAAClC,OAAO,EAAE;;YAGZmC,SAAS,GAAG,IAAI,CAACC,SAAS,EAAE,CAAClF,MAAM;YACzClB,MAAA,CAAAqG,IAAI,CAACC,MAAM,CACPH,SAAS,KAAK,IAAI,CAACxF,UAAU,EAC7B;cAAM,+BAAsBwF,SAAS,oBAAenE,KAAI,CAACrB,UAAU,aAAU;YAAvE,CAAuE,CAAC;YAE5E4F,UAAU,GAAG,IAAI,CAAClE,cAAc,CAACmE,OAAO,CAAC,CAAC,CAAC,CAAChG,KAAK,CAACY,KAAK,CAAC,CAAC,CAAC;YAC1DqF,SAAS,GAAG3G,EAAE,CAACuG,IAAI,CAACK,aAAa,CAACH,UAAU,CAAC;YAInD,IAAI,IAAI,CAACtF,IAAI,EAAE;cACX0F,eAAe,GAAG7G,EAAE,CAAC8G,YAAY,CAACD,eAAe,CAAC;gBAAE1F,IAAI,EAAE;cAAI,CAAC,CAAC;aACnE,MACI;cACD0F,eAAe,GAAG7G,EAAE,CAAC8G,YAAY,CAACD,eAAe,CAAC,EAAE,CAAC;;YAGzD,IAAI,CAACE,aAAa,GAAG/G,EAAE,CAACoC,UAAU,CAAC;cAC/BS,MAAM,EAAE,CACJ7C,EAAE,CAAC6C,MAAM,CAACmE,KAAK,CAAC;gBACZP,UAAU,EAAE,CAACE,SAAS,CAAC;gBACvBM,KAAK,EAAEnB,MAAM,CAACoB,UAAU;gBACxBzD,UAAU,EAAE,MAAM;gBAClB0D,iBAAiB,EAAEN,eAAe;gBAClCO,OAAO,EAAE;eACZ,CAAC,EACFpH,EAAE,CAAC6C,MAAM,CAACmE,KAAK,CAAC;gBACZG,iBAAiB,EAAEN,eAAe;gBAClCO,OAAO,EAAE,KAAK;gBACd3D,UAAU,EAAE,SAAS;gBACrBwD,KAAK,EAAE,IAAI,CAACpG;eACf,CAAC;aAET,CAAC;YAEIwG,SAAS,GAAGrH,EAAE,CAAC6F,KAAK,CAACyB,IAAI,CAACxB,MAAM,CAACyB,YAAY,CAAC;YACpD;YAEA,IAAI,CAACR,aAAa,CAACS,OAAO,CAAC;cACvBH,SAAS,EAAAA,SAAA;cACT;cACAI,IAAI,EAAE,yBAAyB;cAC/BC,OAAO,EAAE,CAAC,UAAU;aACvB,CAAC;YAEF,IAAI,EAAE5B,MAAM,CAAC6B,SAAS,GAAG,CAAC,CAAC,EAAE;cACzB,MAAM,IAAI5D,KAAK,CACf,2DAA2D,CAC1D;;YAGC6D,SAAS,GAAG,IAAI,CAAC9E,YAAY,CAAC+E,KAAK,CAAC/B,MAAM,CAAC6B,SAAS,CAAC;YACrDG,cAAc,GAAG,IAAI,CAACxD,iBAAiB,CAACuD,KAAK,CAAC/B,MAAM,CAAC6B,SAAS,CAAC;YASrD,qBAAM,IAAI,CAACZ,aAAa,CAACgB,UAAU,CAACH,SAAS,EAAE;cAC3DI,MAAM,EAAElC,MAAM,CAACkC,MAAM;cACrBF,cAAc,EAAAA,cAAA;cACd/B,SAAS,EAAAA;aACZ,CAAC;;YAJIkC,OAAO,GAAGrG,EAAA,CAAAsG,IAAA,EAId;YAEIC,UAAU,GAAGnI,EAAE,CAACoC,UAAU,EAAE;YAClC+F,UAAU,CAACC,GAAG,CAAC,IAAI,CAAC7F,cAAc,CAAC;YACnC4F,UAAU,CAACC,GAAG,CAAC,IAAI,CAACrB,aAAa,CAAC;YAClC,IAAI,CAACnE,KAAK,GAAGuF,UAAU;YAEvBd,SAAS,CAAC1D,OAAO,EAAE,CAAC,CAAC;YAErB,sBAAO,IAAI,CAACf,KAAK;;;;GACpB;EAED;;;EAGOf,kBAAA,CAAAa,SAAA,CAAA2F,cAAc,GAArB;IACI,KAAK,IAAI9G,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACV,UAAU,EAAEU,CAAC,EAAE,EAAE;MACtC,IAAI,CAACe,QAAQ,CAACf,CAAC,CAAC,GAAG,EAAE;;EAE7B,CAAC;EAEMM,kBAAA,CAAAa,SAAA,CAAA4F,QAAQ,GAAf,UAAgBC,KAAa,EAAE3H,KAAa;IACxC,IAAI,CAACmC,SAAS,CAACC,MAAM,CAACuF,KAAK,CAAC,GAAG3H,KAAK;EACxC,CAAC;EAEMiB,kBAAA,CAAAa,SAAA,CAAA8F,SAAS,GAAhB,UAAiBxF,MAAgB;IAC7B,IAAI,CAACD,SAAS,CAACC,MAAM,GAAGA,MAAM;IAC9B,IAAI,CAACqF,cAAc,EAAE;EACzB,CAAC;EAEMxG,kBAAA,CAAAa,SAAA,CAAA+F,QAAQ,GAAf,UAAgBF,KAAa;IACzB,OAAO,IAAI,CAACxF,SAAS,CAACC,MAAM,CAACuF,KAAK,CAAC;EACvC,CAAC;EAEM1G,kBAAA,CAAAa,SAAA,CAAA4D,SAAS,GAAhB;IACI,OAAO,IAAI,CAACvD,SAAS,CAACC,MAAM;EAChC,CAAC;EAEMnB,kBAAA,CAAAa,SAAA,CAAAgG,OAAO,GAAd,UAAeC,IAAY;IACvB,IAAI,CAAC5F,SAAS,CAAC6F,SAAS,GAAGD,IAAI;EACnC,CAAC;EAEM9G,kBAAA,CAAAa,SAAA,CAAAmG,OAAO,GAAd;IACI,OAAO,IAAI,CAAC9F,SAAS,CAAC6F,SAAS;EACnC,CAAC;EAEM/G,kBAAA,CAAAa,SAAA,CAAAoG,YAAY,GAAnB;IAAA,IAAA5G,KAAA;IACI,IAAM6G,OAAO,GAAG,IAAIC,OAAO,CAAC,UAACC,OAAO,EAAEC,MAAM;MACxChH,KAAI,CAAC6E,aAAa,CAAC+B,YAAY,GAAG,IAAI;MACtC5G,KAAI,CAACiE,qBAAqB,GAAG8C,OAAO;MACpC;IACJ,CAAC,CAAC;IAEF,OAAOF,OAAO;EAClB,CAAC;EAEMlH,kBAAA,CAAAa,SAAA,CAAAiB,OAAO,GAAd;IACI,IAAI,CAACoD,aAAa,CAACpD,OAAO,EAAE;IAC5B7B,MAAA,CAAAY,SAAA,CAAMiB,OAAO,CAAAxB,IAAA,MAAE;EACnB,CAAC;EAED;;;EAGaN,kBAAA,CAAAa,SAAA,CAAAyG,yBAAyB,GAAtC;;;;;;;YACUC,YAAY,GAAG,IAAI,CAAC9E,iBAAiB,CAAC+E,QAAQ,CAAC,UAAOC,OAAwB;cAAA,OAAAC,SAAA,CAAArH,KAAA;;kBAChF,sBAAQoH,OAAuD,CAAC9D,EAAE;;;aACrE,CAAC;YACIgE,YAAY,GAAG,IAAI,CAAClF,iBAAiB,CAAC+E,QAAQ,CAAC,UAAOC,OAAwB;cAAA,OAAAC,SAAA,CAAArH,KAAA;;kBAChF,sBAAQoH,OAAuD,CAAC7D,EAAE;;;aACrE,CAAC;YAGIkC,SAAS,GAAGlG,IAAI,CAACgI,GAAG,CAACD,YAAY,CAACE,IAAI,EAAE,EAAE,CAAC;YAC3CC,UAAU,GAAGlI,IAAI,CAACkD,IAAI,CAAC6E,YAAY,CAACE,IAAI,GAAG/B,SAAS,CAAC;YAErDiC,QAAQ,GAAGR,YAAY,CAACvB,KAAK,CAACF,SAAS,CAAC;YACxCkC,QAAQ,GAAGL,YAAY,CAAC3B,KAAK,CAACF,SAAS,CAAC;YAClC,qBAAMiC,QAAQ,CAACE,QAAQ,EAAE;;YAA/BC,GAAG,GAAGnI,EAAA,CAAAsG,IAAA,EAAyB;YACzB,qBAAM2B,QAAQ,CAACC,QAAQ,EAAE;;YAA/BE,GAAG,GAAGpI,EAAA,CAAAsG,IAAA,EAAyB;YAC/B+B,IAAI,GAAG,EAAE;YACTC,IAAI,GAAG,EAAE;YAEN3I,CAAC,GAAG,CAAC;;;kBAAEA,CAAC,GAAGoI,UAAU;YAEH,qBAAMI,GAAG,CAACI,IAAI,EAAE;;YAAjCC,cAAc,GAAGxI,EAAA,CAAAsG,IAAA,EAAgB;YACjCmC,wBAAwB,GAAG,IAAI,CAACtD,aAAa,CAACvD,OAAO,CAAC4G,cAAc,CAACE,KAAK,CAAc;YACxFC,OAAO,GAAGF,wBAAwB,CAACG,MAAM,CAAC,CAAC,CAAC;YAClDP,IAAI,CAACrG,IAAI,CAAC2G,OAAO,CAAC;YAGK,qBAAMP,GAAG,CAACG,IAAI,EAAE;;YAAjCM,cAAc,GAAG7I,EAAA,CAAAsG,IAAA,EAAgB;YACjCwC,OAAO,GAAGD,cAAc,CAACH,KAAK,CAACE,MAAM,CAAC,CAAC,CAAC;YAC9CN,IAAI,CAACtG,IAAI,CAAC8G,OAAO,CAAC;YAElB;YACAN,cAAc,CAACE,KAAK,CAAC3G,OAAO,EAAE;YAC9B0G,wBAAwB,CAAC1G,OAAO,EAAE;YAClC8G,cAAc,CAACH,KAAK,CAAC3G,OAAO,EAAE;;;YAfFpC,CAAC,EAAE;;;YAmB7BoJ,SAAS,GAAG3K,EAAE,CAACkF,MAAM,CAACgF,IAAI,CAAC;YAC3BU,WAAW,GAAG5K,EAAE,CAACkF,MAAM,CAAC+E,IAAI,CAAC;YAEnC;YACA,IAAIN,UAAU,KAAK,CAAC,EAAE;cAClB,KAASpI,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG0I,IAAI,CAAC7I,MAAM,EAAEG,CAAC,EAAE,EAAE;gBAClC0I,IAAI,CAAC1I,CAAC,CAAC,CAACoC,OAAO,EAAE;gBACjBuG,IAAI,CAAC3I,CAAC,CAAC,CAACoC,OAAO,EAAE;;;YAIzB,sBAAO;cAAEgH,SAAS,EAAAA,SAAA;cAAEC,WAAW,EAAAA;YAAA,CAAE;;;;GACpC;EAED;;;EAGO/I,kBAAA,CAAAa,SAAA,CAAAmI,OAAO,GAAd,UAAe1J,IAAY;IACvB,IAAI,CAACA,IAAI,GAAGd,UAAU,CAACc,IAAI,CAAC;EAChC,CAAC;EACL,OAAAU,kBAAC;AAAD,CAAC,CA3YuCzB,kBAAA,CAAA0K,eAAe;AAA1CC,OAAA,CAAAlJ,kBAAA,GAAAA,kBAAA;AA6Yb,SAAsBmJ,eAAeA,CAAC/I,QAA2B,EAAEgJ,YAA2B;;;;;;UACxE,qBAAM7K,kBAAA,CAAA8K,sBAAsB,CAACD,YAAY,CAAC;;UAAtDE,SAAS,GAAGvJ,EAAA,CAAAsG,IAAA,EAA0C;UAC5D,sBAAO,IAAIrG,kBAAkB,CAACsJ,SAAS,EAAElJ,QAAQ,CAAC;;;;;AAFtD8I,OAAA,CAAAC,eAAA,GAAAA,eAAA","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}